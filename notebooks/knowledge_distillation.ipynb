{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path, PosixPath\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller:\n",
    "    def __init__(self, tuning_parameters, labelling_parameters, name=None):\n",
    "        self.tuning_parameters = tuning_parameters\n",
    "        self.labelling_parameters = labelling_parameters\n",
    "\n",
    "    def tune_model(self, model, dataset, name):\n",
    "        return tuned_model\n",
    "\n",
    "    def label_dataset(self, model, unlabelled_dataset):\n",
    "        return labelled_dataset\n",
    "\n",
    "    def distil(self, big_model, small_model, labelled_dataset_1, unlabelled_dataset_2, job_name=None):\n",
    "        print(\"Tuning Big Model\")\n",
    "        tuned_big_model = self.tune_model(big_model, labelled_dataset_1, name=job_name+\"-big-tune\")\n",
    "\n",
    "        print(\"Tuning Small Model\")\n",
    "        tuned_small_model = self.tune_model(small_model, labelled_dataset_1, name=job_name+\"-small-tune\")\n",
    "\n",
    "        print(\"Labelling Dataset\")\n",
    "        self.label_dataset(tuned_big_model, unlabelled_dataset_2)\n",
    "\n",
    "        print(\"Retuning Small model\")\n",
    "        self.tune_model(tuned_small_model, unlabelled_dataset_2, name=job_name+\"-small-retune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_model_labelled = [\n",
    "    \"path: datasets/FebSynth # dataset root dir\",\n",
    "    \"train: train/images # train images (relative to 'path')\",\n",
    "    \"val: val/images # val images (relative to 'path')\",\n",
    "    \"test: test/images # test images (optional)\",\n",
    "    \"# Classes\",\n",
    "    \"names:\",\n",
    "    \" 0: pedestrian\",\n",
    "    \" 1: people\",\n",
    "    \" 2: bicycle\",\n",
    "    \" 3: car\",\n",
    "    \" 4: van\",\n",
    "    \" 5: truck\",\n",
    "    \" 6: tricycle\",\n",
    "    \" 7: awning-tricycle\",\n",
    "    \" 8: bus\",\n",
    "    \" 9: motor\",\n",
    "]\n",
    "with open(\"ultralytics/ultralytics/cfg/datasets/FebSynth.yaml\", \"wt\") as yaml_out:\n",
    "    yaml_out.writelines(s + '\\n' for s in lines_model_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(itertools.islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "class YOLOv8Distiller(Distiller):\n",
    "    def _init_(self, tuning_parameters, labelling_parameters):\n",
    "        super()._init_(tuning_parameters, labelling_parameters)\n",
    "    \n",
    "    def tune_model(self, model, dataset, name):\n",
    "        # Abuse of notation, converting model path to pt model\n",
    "        model = YOLO(model)\n",
    "        \n",
    "        model.train(data=dataset, name=name, **self.tuning_parameters)\n",
    "        tuned_model = PosixPath.joinpath(PosixPath(model.trainer.save_dir, \"weights/best.pt\"))\n",
    "        return tuned_model\n",
    "    \n",
    "    def label_dataset(self, model, unlabelled_dataset):\n",
    "        # Abuse of notation, converting model path to pt model\n",
    "        model = YOLO(model)\n",
    "        unlabelled_dataset = \"datasets/\"+unlabelled_dataset.split(\".\")[0]+\"/train/\"\n",
    "        images = glob(unlabelled_dataset+\"images/*\")\n",
    "        batches = list(batched(images, self.labelling_parameters[\"batch_size\"]))\n",
    "        for batch in tqdm(batches):\n",
    "            results = model(batch)\n",
    "            for i, result in enumerate(results):\n",
    "                lines = []\n",
    "                for cls, box in zip(result.boxes.cls, result.boxes.xywhn):\n",
    "                    line = f\"{int(cls)}\"\n",
    "                    for j in list(box):\n",
    "                        line = line+f\" {float(j):6.6f}\"\n",
    "                    lines.append(line)\n",
    "\n",
    "                label_filename = unlabelled_dataset+\"labels/\"+batch[i].split(\"/\")[-1].split(\".\")[0]+\".txt\"\n",
    "\n",
    "                with open(label_filename, \"wt\") as f:\n",
    "                    [f.write(line+\"\\n\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise Exception(\"Comment out this exception to run the labelling\")\n",
    "model_labelled_dir = \"datasets/FebSynth\"\n",
    "\n",
    "images = glob(\"//Feb Data//*.png\")\n",
    "random.shuffle(images)\n",
    "\n",
    "os.makedirs(model_labelled_dir, exist_ok=True)\n",
    "os.makedirs(model_labelled_dir+\"/train/images\", exist_ok=True)\n",
    "os.makedirs(model_labelled_dir+\"/train/labels\", exist_ok=True)\n",
    "os.makedirs(model_labelled_dir+\"/val/images\", exist_ok=True)\n",
    "os.makedirs(model_labelled_dir+\"/val/labels\", exist_ok=True)\n",
    "\n",
    "for image in images:\n",
    "    stem = Path(image).stem\n",
    "\n",
    "    shutil.copy(image, model_labelled_dir+\"/train/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "training_results = {\n",
    "    \"big-tune\":pd.read_csv(\"runs/detect/kd-big-tune/results.csv\").rename(columns=lambda x: x.strip()),\n",
    "    \"small-tune\":pd.read_csv(\"runs/detect/kd-small-tune/results.csv\").rename(columns=lambda x: x.strip()),\n",
    "    \"small-retune\":pd.read_csv(\"runs/detect/kd-small-retune/results.csv\").rename(columns=lambda x: x.strip()),\n",
    "}\n",
    "\n",
    "for column in [\n",
    "    \"metrics/precision(B)\",\n",
    "    \"metrics/recall(B)\",\n",
    "    \"metrics/mAP50(B)\",\n",
    "    \"metrics/mAP50-95(B)\",\n",
    "]:\n",
    "    metric = column.split(\"/\")[1].split(\"(\")[0]\n",
    "    d = {\"epochs\":[], metric: [], \"model\": []}\n",
    "    for key, df in training_results.items():\n",
    "        d[\"epochs\"].extend(list(df.index))\n",
    "        d[metric].extend(list(df[column]))\n",
    "        d[\"model\"].extend([key]*len(df))\n",
    "    data = pd.DataFrame(d)\n",
    "    sns.lineplot(data=data,x=\"epochs\",y=metric,hue=\"model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"big-tune\":\"runs/detect/kd-big-tune/weights/best.pt\",\n",
    "    \"small-tune\":\"runs/detect/kd-small-tune/weights/best.pt\",\n",
    "    \"small-retune\":\"runs/detect/kd-small-retune/weights/best.pt\",\n",
    "}\n",
    "\n",
    "for key, model_str in models.items():\n",
    "    print(\"---------------\")\n",
    "    print(f\"EVALUATING {key} ON TEST SET\")\n",
    "    print(\"---------------\")\n",
    "    model = YOLO(model_str)\n",
    "    model.val(split=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
